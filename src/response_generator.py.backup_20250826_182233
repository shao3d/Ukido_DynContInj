from pathlib import Path
from typing import List, Dict, Optional
from config import Config
from openrouter_client import OpenRouterClient
from standard_responses import DEFAULT_FALLBACK
from offers_catalog import get_offer, get_tone_adaptation, get_dynamic_example
import re

class ResponseGenerator:
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–∞:
    - –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–æ—É—Ç–µ—Ä–∞ (status=success, documents, decomposed_questions)
    - –ü–æ–¥–≥—Ä—É–∂–∞–µ—Ç MD –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ data/documents_compressed (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏)
    - –°–æ–±–∏—Ä–∞–µ—Ç —Å–æ—Å—Ç–∞–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç (—Å–∏—Å—Ç–µ–º–Ω–∞—è —Ä–æ–ª—å + –¥–æ–∫—É–º–µ–Ω—Ç—ã + –∏—Å—Ç–æ—Ä–∏—è[–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10] + –≤–æ–ø—Ä–æ—Å—ã)
    - –í—ã–∑—ã–≤–∞–µ—Ç LLM –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    """

    def __init__(self, docs_dir: Optional[Path] = None):
        cfg = Config()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Claude 3.5 Haiku –¥–ª—è –æ–¥–Ω–æ—ç—Ç–∞–ø–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Å—Ç–∏–ª–µ–º
        self.client = OpenRouterClient(
            cfg.OPENROUTER_API_KEY,
            seed=cfg.SEED,
            max_tokens=400,  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ 100-150 —Å–ª–æ–≤
            temperature=0.1,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            model="anthropic/claude-3.5-haiku",  # Claude Haiku –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        )
        self.docs_dir = docs_dir or (Path(__file__).parent.parent / "data" / "documents_compressed")
        self.history_limit = cfg.HISTORY_LIMIT  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞

    async def generate(
        self,
        router_result: Dict,
        history: Optional[List[Dict[str, str]]] = None,
    ) -> str:
        if router_result.get("status") != "success":
            return DEFAULT_FALLBACK

        docs = router_result.get("documents") or []
        questions = router_result.get("decomposed_questions") or []
        if not docs or not questions:
            return DEFAULT_FALLBACK

        # –ü–æ–ª—É—á–∞–µ–º user_signal –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
        user_signal = router_result.get("user_signal", "exploring_only")
        
        doc_texts = self._load_docs(docs)
        
        # –ó–ê–©–ò–¢–ê –û–¢ –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ô: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å - –æ—Ç–∫–∞–∑—ã–≤–∞–µ–º—Å—è –æ—Ç–≤–µ—á–∞—Ç—å
        if not doc_texts:
            print("‚ö†Ô∏è –ó–ê–©–ò–¢–ê: –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞")
            return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –º–µ–Ω—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –æ —à–∫–æ–ª–µ Ukido?"
        
        # –û–¥–Ω–æ—ç—Ç–∞–ø–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å Claude Haiku + dynamic few-shot
        messages = self._build_messages(doc_texts, questions, history or [], router_result)

        try:
            reply = await self.client.chat(messages)
            cleaned = (reply or "").strip()
            if not cleaned:
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            
            # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            sanitized = self._strip_source_citations(cleaned)
            polished = self._remove_question_headings(sanitized)
            humanized = self._humanize_missing_info(polished)
            no_labels = self._strip_service_labels(humanized)
            no_cta = self._strip_generic_cta(no_labels)
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è (—É–±–∏—Ä–∞–µ–º –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è)
            final_text = self._final_sanitize(no_cta)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –∫–æ–Ω–µ—Ü (–µ—Å–ª–∏ –µ—Å—Ç—å)
            offer = get_offer(user_signal, history)
            if offer and offer["priority"] in ["high", "medium"]:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –¥–æ–±–∞–≤–ª—è—Ç—å offer (rate limiting)
                if self._should_add_offer(user_signal, history, offer):
                    final_text = self._inject_offer(final_text, offer)
            
            return final_text
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –Ω–µ–ø–æ–ª–∞–¥–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."

    def _load_docs(self, docs: List[str]) -> Dict[str, str]:
        """–ß–∏—Ç–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ü–µ–ª–∏–∫–æ–º –∏–∑ data/documents_compressed.
        –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ Router (–¥–æ 4 —à—Ç—É–∫)."""
        texts: Dict[str, str] = {}
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è - —É–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—ã
        unique_docs = list(dict.fromkeys(docs))  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (Router —É–∂–µ –æ–≥—Ä–∞–Ω–∏—á–∏–ª –¥–æ 4)
        docs_to_load = unique_docs
        
        for name in docs_to_load:
            try:
                path = self.docs_dir / name
                content = path.read_text(encoding="utf-8")
                texts[name] = content
            except FileNotFoundError:
                print(f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {name} ({self.docs_dir})")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {name}: {e}")
        return texts

    def _build_messages(
        self,
        doc_texts: Dict[str, str],
        questions: List[str],
        history: List[Dict[str, str]],
        router_result: Dict,
    ) -> List[Dict[str, str]]:
        # –ü–æ–ª—É—á–∞–µ–º user_signal –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Ç–æ–Ω–∞
        user_signal = router_result.get("user_signal", "exploring_only")
        tone_adaptation = get_tone_adaptation(user_signal)
        dynamic_example = get_dynamic_example(user_signal)
        
        # –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è Claude Haiku - —Ñ–∞–∫—Ç—ã + —Å—Ç–∏–ª—å + –∞–¥–∞–ø—Ç–∞—Ü–∏—è
        system_role = (
            "–¢—ã ‚Äî –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –¥–µ—Ç—Å–∫–æ–π —à–∫–æ–ª—ã soft skills Ukido. "
            "–û—Ç–≤–µ—á–∞–π –∂–∏–≤—ã–º —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–º —è–∑—ã–∫–æ–º –æ—Ç –ª–∏—Ü–∞ —à–∫–æ–ª—ã (–∏—Å–ø–æ–ª—å–∑—É–π '–º—ã', –Ω–µ '—è'). "
            "–ì–æ–≤–æ—Ä–∏ –∫–∞–∫ –±—É–¥—Ç–æ –∫–æ–ª–ª–µ–∫—Ç–∏–≤ —à–∫–æ–ª—ã —Å–æ–≤–µ—Ç—É–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—é.\n\n"
            "üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ó–ê–©–ò–¢–ê –û–¢ –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ô:\n"
            "‚Ä¢ –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
            "‚Ä¢ –ù–ò–ö–û–ì–î–ê –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã, —Ü–∏—Ñ—Ä—ã, –¥–µ—Ç–∞–ª–∏\n"
            "‚Ä¢ –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ù–ï–¢ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û:\n"
            "  '–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –º–µ–Ω—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. –ú–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –æ [—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Ç–µ–º–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤]'\n"
            "‚Ä¢ –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π: –∞–¥—Ä–µ—Å–∞, –ø–∞—Ä–∫–æ–≤–∫–∏, –¥–µ—Ç–∞–ª–∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã, —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è\n"
            "‚Ä¢ –í—Å–µ —Ñ–∞–∫—Ç—ã, —Ü–∏—Ñ—Ä—ã, —Ü–µ–Ω—ã ‚Äî –°–¢–†–û–ì–û –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–¥–∞–ø—Ç–∞—Ü–∏—é —Ç–æ–Ω–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if tone_adaptation.get("style"):
            system_role += f"\n\n–ê–î–ê–ü–¢–ê–¶–ò–Ø –¢–û–ù–ê:\n{tone_adaptation['style']}"
            # –í–ê–ñ–ù–û: –£—Å–∏–ª–∏–≤–∞–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Ç–æ–Ω–∞ –¥–ª—è user_signal
            tone_map = {
                "price_sensitive": "üéØ –ö–†–ò–¢–ò–ß–ù–û: –†–æ–¥–∏—Ç–µ–ª—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ü–µ–Ω–µ!\n"
                "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ù–ê–ß–ù–ò –ü–ï–†–í–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï –°–û –°–ö–ò–î–ö–ò!\n"
                "–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –Ω–∞—á–∞–ª–∞:\n"
                "‚Ä¢ '–£ –Ω–∞—Å –µ—Å—Ç—å —Å–∫–∏–¥–∫–∞ 10% –ø—Ä–∏ –æ–ø–ª–∞—Ç–µ –≤—Å–µ–≥–æ –∫—É—Ä—Å–∞ —Å—Ä–∞–∑—É, —á—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–æ...'\n"
                "‚Ä¢ '–•–æ—Ä–æ—à–∞—è –Ω–æ–≤–æ—Å—Ç—å - –¥–æ—Å—Ç—É–ø–Ω–∞ —Ä–∞—Å—Å—Ä–æ—á–∫–∞ –±–µ–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –Ω–∞ 3 –º–µ—Å—è—Ü–∞...'\n"
                "‚Ä¢ '–°–∫–∏–¥–∫–∞ 15% –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ —Ä–µ–±—ë–Ω–∫–∞ –¥–µ–ª–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–µ–µ...'\n"
                "–ó–∞—Ç–µ–º –æ–±—ä—è—Å–Ω–∏ —Ü–µ–Ω–Ω–æ—Å—Ç—å –∏ ROI. –ú–µ–Ω—å—à–µ —ç–º–ø–∞—Ç–∏–∏ - –±–æ–ª—å—à–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –≤—ã–≥–æ–¥!",
                "anxiety_about_child": "üíö –ö–†–ò–¢–ò–ß–ù–û: –†–æ–¥–∏—Ç–µ–ª—å —Ç—Ä–µ–≤–æ–∂–∏—Ç—Å—è –∑–∞ —Ä–µ–±–µ–Ω–∫–∞! –ü–ï–†–í–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —ç–º–ø–∞—Ç–∏—á–Ω—ã–º.\n\n‚ö†Ô∏è –í–ê–ñ–ù–û - –í–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫:\n‚Ä¢ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–æ '–ø–æ–Ω–∏–º–∞–µ–º' –±–æ–ª—å—à–µ 1 —Ä–∞–∑–∞ –∑–∞ –≤–µ—Å—å –¥–∏–∞–ª–æ–≥\n‚Ä¢ –ö–∞–∂–¥—ã–π —Ä–∞–∑ –≤—ã–±–∏—Ä–∞–π –†–ê–ó–ù–£–Æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É —ç–º–ø–∞—Ç–∏–∏\n\n–í–∞—Ä–∏–∞–Ω—Ç—ã –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–≤—ã–±–∏—Ä–∞–π —Ä–∞–∑–Ω—ã–µ):\n‚Ä¢ '–ü–æ–Ω–∏–º–∞–µ–º, –∫–∞–∫ –≤–∞–º —Ç—è–∂–µ–ª–æ –≤–∏–¥–µ—Ç—å, —á—Ç–æ —Ä–µ–±–µ–Ω–æ–∫ —Å—Ç—Ä–∞–¥–∞–µ—Ç...' (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û 1 —Ä–∞–∑)\n‚Ä¢ '–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–ø—Ä–æ—Å—Ç–∞—è —Å–∏—Ç—É–∞—Ü–∏—è –¥–ª—è –ª—é–±–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è...'\n‚Ä¢ '–í–∞—à–∏ –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏—è –∞–±—Å–æ–ª—é—Ç–Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω—ã...'\n‚Ä¢ '–ú–Ω–æ–≥–∏–µ —Ä–æ–¥–∏—Ç–µ–ª–∏ –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ –ø–æ—Ö–æ–∂–∏–µ —á—É–≤—Å—Ç–≤–∞...'\n‚Ä¢ '–¢–∞–∫–∏–µ –æ–ø–∞—Å–µ–Ω–∏—è –∑–Ω–∞–∫–æ–º—ã –±–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –∑–∞–±–æ—Ç–ª–∏–≤—ã—Ö —Ä–æ–¥–∏—Ç–µ–ª–µ–π...'\n‚Ä¢ '–†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è —Ç—Ä–µ–≤–æ–≥–∞ –≤ —Ç–∞–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –ø–æ–Ω—è—Ç–Ω–∞...'\n‚Ä¢ '–í–∞–∂–Ω–æ, —á—Ç–æ –≤—ã —Ç–∞–∫ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã –∫ —Å–æ—Å—Ç–æ—è–Ω–∏—é —Ä–µ–±–µ–Ω–∫–∞...'\n‚Ä¢ '–î–µ—Ç—Å–∫–∏–µ –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏—è –≤—Å–µ–≥–¥–∞ –æ—Ç–∑—ã–≤–∞—é—Ç—Å—è –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —Å–µ—Ä–¥—Ü–µ...'\n\n–ü–û–¢–û–ú —Ä–∞—Å—Å–∫–∞–∂–∏ –∫–∞–∫ —à–∫–æ–ª–∞ –ø–æ–º–æ–≥–∞–µ—Ç —Å –ø–æ–¥–æ–±–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏. –ò—Å–ø–æ–ª—å–∑—É–π –º—è–≥–∫–∏–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π —Ç–æ–Ω.",
                "ready_to_buy": "‚úÖ –ù–ê–ß–ù–ò —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è: '–î–ª—è –∑–∞–ø–∏—Å–∏ –Ω–∞ –∫—É—Ä—Å...' –∏–ª–∏ '–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥ - —ç—Ç–æ...' –ë–ï–ó –ª–∏—à–Ω–µ–π –≤–æ–¥—ã!",
                "exploring_only": "üìö –ë—É–¥—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –ë–ï–ó –Ω–∞–≤—è–∑—á–∏–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∑–∞–ø–∏—Å–∞—Ç—å—Å—è. –≠—Ç–æ –ø–∞—Å—Å–∏–≤–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ - –¥–∞–π –∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –±–µ–∑ –¥–∞–≤–ª–µ–Ω–∏—è."
            }
            if user_signal in tone_map:
                system_role += f"\n\n{tone_map[user_signal]}"

        # –†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        allowed_docs = list(doc_texts.keys())

        # –ü–æ–ª–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–±–µ–∑ —Ç—Ä–∏–º–º–∏–Ω–≥–∞)
        docs_block_lines = []
        for name, text in doc_texts.items():
            docs_block_lines.append(f"=== –î–æ–∫—É–º–µ–Ω—Ç: {name} ===\n{text}\n")
        docs_block = "\n".join(docs_block_lines) if docs_block_lines else "=== –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ==="

        system_content = (
            f"{system_role}\n\n"
            f"–†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(allowed_docs) if allowed_docs else '‚Äî'}\n\n"
            f"=== –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π ===\n{docs_block}\n\n"
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä –µ—Å–ª–∏ –µ—Å—Ç—å
        if dynamic_example:
            system_content += f"=== –ü–†–ò–ú–ï–† –ê–î–ê–ü–¢–ê–¶–ò–ò –°–¢–ò–õ–Ø ===\n{dynamic_example}\n\n"
        
        system_content += (
            "–°—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞:\n"
            "‚Ä¢ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —è–∑—ã–∫ –æ—Ç –ª–∏—Ü–∞ —à–∫–æ–ª—ã (–∏—Å–ø–æ–ª—å–∑—É–π '–º—ã', '—É –Ω–∞—Å', '–Ω–∞—à–∏')\n"
            "‚Ä¢ –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞ –≤–º–µ—Å—Ç–æ –∫–∞–Ω—Ü–µ–ª—è—Ä—Å–∫–∏—Ö\n"
            "‚Ä¢ –°–¢–†–û–ì–û 100-150 —Å–ª–æ–≤! –ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ —Å–≤—ã—à–µ 150 - —ç—Ç–æ –ù–ê–†–£–®–ï–ù–ò–ï\n"
            "‚Ä¢ –ï—Å–ª–∏ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –±–æ–ª—å—à–µ 150 —Å–ª–æ–≤ - —Å–æ–∫—Ä–∞—Ç–∏ –¥–µ—Ç–∞–ª–∏, –æ—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–æ–µ\n\n"
            "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞:\n"
            "‚Ä¢ –ü–ï–†–í–´–ï 2 –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é!\n"
            "‚Ä¢ –ù–∞—á–∏–Ω–∞–π —Å –≥–ª–∞–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –∞ –Ω–µ —Å –≤–≤–æ–¥–Ω—ã—Ö —Å–ª–æ–≤\n"
            "‚Ä¢ –ï—Å–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å —Ä–∞–∑–¥—Ä–∞–∂—ë–Ω - –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–Ω–∏–∑–∏—Ç—å –Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ\n"
            "‚Ä¢ –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è price_sensitive: –ü–ï–†–í–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –°–û –°–ö–ò–î–ö–û–ô!\n"
            "‚Ä¢ –î–µ—Ç–∞–ª–∏ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è - —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n\n"
            "–ü—Ä–∏–º–µ—Ä—ã —Ö–æ—Ä–æ—à–∏—Ö –Ω–∞—á–∞–ª:\n"
            "‚Ä¢ –í–æ–ø—Ä–æ—Å –æ —Ü–µ–Ω–µ ‚Üí '–ú–µ—Å—è—Ü –æ–±—É—á–µ–Ω–∏—è —Å—Ç–æ–∏—Ç 6,000 –≥—Ä–Ω. –ó–∞ —ç—Ç–∏ –¥–µ–Ω—å–≥–∏ —Ä–µ–±—ë–Ω–æ–∫ –ø–æ–ª—É—á–∞–µ—Ç...'\n"
            "‚Ä¢ –°–æ–º–Ω–µ–Ω–∏—è –≤ –ø–æ–ª—å–∑–µ ‚Üí '–î–µ—Ç–∏ —É—á–∞—Ç—Å—è –≤—ã—Å—Ç—É–ø–∞—Ç—å –ø—É–±–ª–∏—á–Ω–æ –∏ —É–ø—Ä–∞–≤–ª—è—Ç—å —ç–º–æ—Ü–∏—è–º–∏. –ü–æ—Å–ª–µ –∫—É—Ä—Å–∞ 85% —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —É–≤–µ—Ä–µ–Ω–Ω–µ–µ...'\n"
            "‚Ä¢ –†–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ ‚Üí '–ü–æ–Ω–∏–º–∞–µ–º –≤–∞—à–∏ –æ–ø–∞—Å–µ–Ω–∏—è –æ —Ü–µ–Ω–µ. –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä—ë–º —á—Ç–æ –≤—Ö–æ–¥–∏—Ç –≤ —Å—Ç–æ–∏–º–æ—Å—Ç—å...'\n\n"
            "–§–∞–∫—Ç—ã –∏ —Ü–∏—Ñ—Ä—ã:\n"
            "‚Ä¢ –í—Å–µ —Ü–∏—Ñ—Ä—ã, —Ü–µ–Ω—ã, –ø—Ä–æ—Ü–µ–Ω—Ç—ã - –¢–û–õ–¨–ö–û –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Ç–æ—á–Ω–æ\n"
            "‚Ä¢ –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π, –Ω–µ –¥–æ–±–∞–≤–ª—è–π –æ—Ç —Å–µ–±—è\n"
            "‚Ä¢ –ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç - —Å–∫–∞–∂–∏ '–í –Ω–∞—à–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö —ç—Ç–æ–≥–æ –Ω–µ—Ç'\n"
            "‚Ä¢ –í–ê–ñ–ù–û: –°–º—è–≥—á–∞–π —Å–ª–∏—à–∫–æ–º —Ç–æ—á–Ω—ã–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã:\n"
            "  - –í–º–µ—Å—Ç–æ '85%', '76%', '82%' ‚Üí '–±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ', '–º–Ω–æ–≥–∏–µ', '–æ–∫–æ–ª–æ 80%'\n"
            "  - –í–º–µ—Å—Ç–æ '–≤ 2.3 —Ä–∞–∑–∞' ‚Üí '–≤ –¥–≤–∞ —Ä–∞–∑–∞', '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ', '—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ'\n"
            "  - –ù–ò–ö–û–ì–î–ê –Ω–µ –≥–æ–≤–æ—Ä–∏ '4.3 –≥—Ä–∏–≤–Ω—ã —ç—Ñ—Ñ–µ–∫—Ç–∞' ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π '–æ–∫—É–ø–∞–µ—Ç—Å—è –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ'\n"
            "  - –ò—Å–ø–æ–ª—å–∑—É–π: '–±–æ–ª–µ–µ –ø–æ–ª–æ–≤–∏–Ω—ã', '7 –∏–∑ 10', '–ø–æ–¥–∞–≤–ª—è—é—â–µ–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ'\n"
            "‚Ä¢ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –ø—Å–µ–≤–¥–æ—Ç–æ—á–Ω—ã–µ —Ü–∏—Ñ—Ä—ã —Å –¥–µ—Å—è—Ç–∏—á–Ω—ã–º–∏ (2.3, 4.3, 1.7)\n"
            "‚Ä¢ –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–µ–Ω—ã (6000 –≥—Ä–Ω) –æ—Å—Ç–∞–≤–ª—è–π –∫–∞–∫ –µ—Å—Ç—å - —ç—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã\n\n"
            "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–æ–≤:\n"
            "‚Ä¢ –¢—ã –≤–∏–¥–∏—à—å –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10 —Å–æ–æ–±—â–µ–Ω–∏–π\n"
            "‚Ä¢ –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π —Ç—ã —É–∂–µ –æ—Ç–≤–µ—á–∞–ª, –∏–ª–∏ –ø—Ä–æ—Å–∏—Ç –ø–æ–≤—Ç–æ—Ä–∏—Ç—å/—É—Ç–æ—á–Ω–∏—Ç—å:\n"
            "  - –í–µ–∂–ª–∏–≤–æ –Ω–∞–ø–æ–º–Ω–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∏—Å–ø–æ–ª—å–∑—É—è: '–ö–∞–∫ —è —É–ø–æ–º–∏–Ω–∞–ª...', '–ù–∞–ø–æ–º–Ω—é, —á—Ç–æ...', '–î–∞, –µ—â–µ —Ä–∞–∑ - ...'\n"
            "  - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –≥—Ä—É–±—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ —Ç–∏–ø–∞ '–≤—ã —É–∂–µ —Å–ø—Ä–∞—à–∏–≤–∞–ª–∏' –∏–ª–∏ '—è —É–∂–µ –æ—Ç–≤–µ—á–∞–ª'\n"
            "‚Ä¢ –ê–¥–∞–ø—Ç–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∫ –ø—Ä–∏—á–∏–Ω–µ –ø–æ–≤—Ç–æ—Ä–∞ (–∑–∞–±—ã–ª/–Ω–µ –ø–æ–Ω—è–ª/—É—Ç–æ—á–Ω—è–µ—Ç)\n\n"
            "–í–ê–ñ–ù–û - –†–∞–±–æ—Ç–∞ —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞:\n"
            "‚Ä¢ –ò–ì–ù–û–†–ò–†–£–ô —Å—Ç–∞—Ä—ã–µ offtopic –≤–æ–ø—Ä–æ—Å—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ (–ø–∞—Ä–∫–æ–≤–∫–∞, —Ñ—É—Ç–±–æ–ª, –ø–æ–≥–æ–¥–∞)\n"
            "‚Ä¢ –ù–ï –£–ü–û–ú–ò–ù–ê–ô –≤ –Ω–æ–≤–æ–º –æ—Ç–≤–µ—Ç–µ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã –∫–∞–∫ offtopic\n"
            "‚Ä¢ –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –¢–û–õ–¨–ö–û –Ω–∞ —Ç–µ–∫—É—â–µ–º –≤–æ–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"
            "‚Ä¢ –ü—Ä–∏–º–µ—Ä –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û: '–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –Ω–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞—Ä–∫–æ–≤–∫–µ. –î–ª—è –∑–∞—á–∏—Å–ª–µ–Ω–∏—è –Ω—É–∂–Ω—ã...'\n"
            "‚Ä¢ –ü—Ä–∏–º–µ—Ä –ü–†–ê–í–ò–õ–¨–ù–û: '–î–ª—è –∑–∞—á–∏—Å–ª–µ–Ω–∏—è –Ω—É–∂–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã...'\n\n"
            "–ò–∑–±–µ–≥–∞–π:\n"
            "‚Ä¢ –í–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤\n"
            "‚Ä¢ –ö–ª–∏—à–µ: '–ó–Ω–∞–µ—Ç–µ', '–ú–Ω–æ–≥–∏–µ —Ä–æ–¥–∏—Ç–µ–ª–∏ –æ—Ç–º–µ—á–∞—é—Ç', '—Ç–∞–∫ —á—Ç–æ', '–Ω–µ –ø–µ—Ä–µ–∂–∏–≤–∞–π—Ç–µ'\n"
            "‚Ä¢ –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫: '–æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è', '–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è', '–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è'\n"
            "‚Ä¢ –ü–æ–≤—Ç–æ—Ä–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n"
            "‚Ä¢ –ù–∞–≤—è–∑—á–∏–≤—ã—Ö CTA –≤ –∫–æ–Ω—Ü–µ ('–ü–∏—à–∏—Ç–µ', '–ó–≤–æ–Ω–∏—Ç–µ', '–û—Å—Ç–∞–ª–∏—Å—å –≤–æ–ø—Ä–æ—Å—ã?')\n"
            "‚Ä¢ –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π ('–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ', '–ü—Ä–∏–≤–µ—Ç') –µ—Å–ª–∏ –¥–∏–∞–ª–æ–≥ —É–∂–µ –Ω–∞—á–∞–ª—Å—è - —Å—Ä–∞–∑—É –æ—Ç–≤–µ—á–∞–π –ø–æ —Å—É—Ç–∏\n\n"
            "–ü—Ä–∏–º–µ—Ä—ã –∑–∞–º–µ–Ω:\n"
            "‚Ä¢ '–æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è' ‚Üí '–¥–µ–ª–∞–µ–º'\n"
            "‚Ä¢ '–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å' ‚Üí '–º–æ–∂–Ω–æ'\n"
            "‚Ä¢ '–Ω–∞—à–∏ –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–∏' ‚Üí '–Ω–∞—à–∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–∏'\n"
        )

        messages: List[Dict[str, str]] = [{"role": "system", "content": system_content}]

        # –ò—Å—Ç–æ—Ä–∏—è: —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
        trimmed_history = history[-self.history_limit :] if len(history) > self.history_limit else history
        if trimmed_history:
            messages.extend(trimmed_history)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ—Ü–∏–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        social_context = router_result.get("social_context")
        social_instruction = ""
        if social_context:
            # Router —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–∏–ª –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π social_context (greeting –∏–ª–∏ repeated_greeting)
            # –ë–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏
            social_map = {
                "greeting": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–∑–¥–æ—Ä–æ–≤–∞–ª—Å—è. –ù–∞—á–Ω–∏ –æ—Ç–≤–µ—Ç —Å –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è.",
                "repeated_greeting": "–í–ê–ñ–ù–û: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–¥–æ—Ä–æ–≤–∞–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ. –ù–ï –∑–¥–æ—Ä–æ–≤–∞–π—Å—è —Å–Ω–æ–≤–∞! –ú–æ–∂–µ—à—å –º—è–≥–∫–æ –æ—Ç–º–µ—Ç–∏—Ç—å —ç—Ç–æ ('–ú—ã —É–∂–µ –ø–æ–∑–¥–æ—Ä–æ–≤–∞–ª–∏—Å—å :)' –∏–ª–∏ '–ï—â–µ —Ä–∞–∑ –∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ!'), –∑–∞—Ç–µ–º —Å—Ä–∞–∑—É –æ—Ç–≤–µ—á–∞–π –ø–æ —Å—É—Ç–∏ –≤–æ–ø—Ä–æ—Å–∞.",
                "thanks": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏–ª. –ù–∞—á–Ω–∏ —Å –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏ –∏–ª–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø–æ–º–æ—á—å.",
                "apology": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏–∑–≤–∏–Ω–∏–ª—Å—è. –ù–∞—á–Ω–∏ —Å —É—Å–ø–æ–∫–∞–∏–≤–∞—é—â–µ–π —Ñ—Ä–∞–∑—ã, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–µ–π —á—Ç–æ –≤—Å—ë —Ö–æ—Ä–æ—à–æ –∏ –Ω–µ —Å—Ç–æ–∏—Ç –±–µ—Å–ø–æ–∫–æ–∏—Ç—å—Å—è.",
                "farewell": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—â–∞–µ—Ç—Å—è. –î–æ–±–∞–≤—å –ø—Ä–æ—â–∞–Ω–∏–µ –≤ –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞."
            }
            social_instruction = social_map.get(social_context, "") + "\n"
        
        # Fallback –¥–ª—è –ø—É—Å—Ç—ã—Ö questions –Ω–∞ –æ—Å–Ω–æ–≤–µ user_signal
        if not questions:
            user_signal = router_result.get("user_signal", "exploring_only")
            if user_signal == "ready_to_buy":
                questions = ["–ù–∞ —á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤—ã —Å–æ–≥–ª–∞—Å–Ω—ã? –•–æ—Ç–∏—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∫—É—Ä—Å –∏–ª–∏ —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π?"]
            elif user_signal == "price_sensitive":
                questions = ["–ö–∞–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ —Å–∫–∏–¥–∫–∞—Ö –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?"]
            elif user_signal == "anxiety_about_child":
                questions = ["–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º —Ä–µ–±—ë–Ω–∫–µ - —á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤–∞—Å –±–µ—Å–ø–æ–∫–æ–∏—Ç?"]
            else:
                questions = ["–ß–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –º–æ–≥—É –ø–æ–º–æ—á—å? –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –æ —à–∫–æ–ª–µ Ukido?"]
        
        questions_block = "\n".join(f"- {q}" for q in questions)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è price_sensitive
        price_instruction = ""
        if router_result.get("user_signal") == "price_sensitive":
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            original_msg = router_result.get("original_message", "").lower().strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            word_count = len(original_msg.split())
            
            # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
            questions_text = " ".join(questions).lower()
            price_keywords = ["—Ü–µ–Ω", "—Å—Ç–æ–∏", "—Å–∫–∏–¥–∫", "–¥–æ—Ä–æ–≥", "–æ–ø–ª–∞—Ç", "—Ä–∞—Å—Å—Ä–æ—á–∫", "–≥—Ä–Ω", "–≥—Ä–∏–≤–µ–Ω", "—Ç—ã—Å—è—á", "–±—é–¥–∂–µ—Ç"]
            
            # –û—Ç–ª–∞–¥–∫–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ª–æ–≥–∏–∫–∏
            print(f"üîç DEBUG price_sensitive: original='{original_msg}', words={word_count}")
            
            # –£–º–Ω–∞—è –ª–æ–≥–∏–∫–∞: –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–ø–ª–∏–∫–∏ –æ —Ü–µ–Ω–µ –≤—Å–µ–≥–¥–∞ —Ç—Ä–µ–±—É—é—Ç —Å–∫–∏–¥–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
            if word_count <= 2 and any(keyword in original_msg for keyword in ["–¥–æ—Ä–æ–≥", "—Å–∫–æ–∫", "—Å—Ç–æ–∏", "—Ü–µ–Ω"]):
                # –£–ª—å—Ç—Ä–∞-–∫–æ—Ä–æ—Ç–∫–∞—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ —Ü–µ–Ω—É - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å–∫–∏–¥–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
                price_instruction = (
                    "üî¥ –ö–†–ò–¢–ò–ß–ù–û: –ö–æ—Ä–æ—Ç–∫–∞—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ —Ü–µ–Ω—É!\n"
                    "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –Ω–∞—á–Ω–∏ –ü–ï–†–í–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï —Å–æ —Å–∫–∏–¥–∫–∏ –∏–ª–∏ —Ä–∞—Å—Å—Ä–æ—á–∫–∏!\n"
                    "–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä–µ–ø–ª–∏–∫:\n"
                    "‚Ä¢ '–î–æ—Ä–æ–≥–æ' ‚Üí '–•–æ—Ä–æ—à–∞—è –Ω–æ–≤–æ—Å—Ç—å - –µ—Å—Ç—å —Å–∫–∏–¥–∫–∞ 10% –ø—Ä–∏ –æ–ø–ª–∞—Ç–µ –∫—É—Ä—Å–∞ —Å—Ä–∞–∑—É...'\n"
                    "‚Ä¢ '–°–∫–æ–∫ —Å—Ç–æ–∏—Ç' ‚Üí '–ú–µ—Å—è—Ü –∑–∞–Ω—è—Ç–∏–π –æ—Ç 6,000 –≥—Ä–Ω, –Ω–æ —Å —É—á—ë—Ç–æ–º —Å–∫–∏–¥–∫–∏ 10%...'\n\n"
                )
            elif any(keyword in questions_text for keyword in price_keywords):
                # –í–æ–ø—Ä–æ—Å –æ —Ü–µ–Ω–µ - —Å–∫–∏–¥–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
                price_instruction = (
                    "‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: –†–æ–¥–∏—Ç–µ–ª—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ü–µ–Ω–µ –∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏!\n"
                    "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –Ω–∞—á–Ω–∏ –ü–ï–†–í–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï —Å–æ —Å–∫–∏–¥–∫–∏ –∏–ª–∏ —Ä–∞—Å—Å—Ä–æ—á–∫–∏!\n"
                    "–ü—Ä–∏–º–µ—Ä—ã: '–•–æ—Ä–æ—à–∞—è –Ω–æ–≤–æ—Å—Ç—å - —É –Ω–∞—Å –µ—Å—Ç—å —Å–∫–∏–¥–∫–∞ 10% –ø—Ä–∏ –æ–ø–ª–∞—Ç–µ –∫—É—Ä—Å–∞...'\n"
                    "–∏–ª–∏ '–î–æ—Å—Ç—É–ø–Ω–∞ —Ä–∞—Å—Å—Ä–æ—á–∫–∞ –±–µ–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –Ω–∞ 3 –º–µ—Å—è—Ü–∞...'\n\n"
                )
            else:
                # –í–æ–ø—Ä–æ—Å –ù–ï –æ —Ü–µ–Ω–µ - —É–ø–æ–º—è–Ω–∏ —Å–∫–∏–¥–∫–∏ –º—è–≥–∫–æ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –∏–ª–∏ –∫–æ–Ω—Ü–µ
                price_instruction = (
                    "üí° –†–æ–¥–∏—Ç–µ–ª—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ü–µ–Ω–µ, –Ω–æ –≤–æ–ø—Ä–æ—Å –Ω–µ –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏.\n"
                    "–°–Ω–∞—á–∞–ª–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ —Å—É—â–µ—Å—Ç–≤—É, –∑–∞—Ç–µ–º –º—è–≥–∫–æ —É–ø–æ–º—è–Ω–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–∫–∏–¥–∫–∏ –∏–ª–∏ —Ä–∞—Å—Å—Ä–æ—á–∫—É.\n"
                    "–ü—Ä–∏–º–µ—Ä: –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–æ–±–∞–≤—å '–ö—Å—Ç–∞—Ç–∏, —É –Ω–∞—Å —Å–µ–π—á–∞—Å –µ—Å—Ç—å —Å–∫–∏–¥–∫–∞ 10%...'\n\n"
                )
        
        messages.append(
            {
                "role": "user",
                "content": (
                    social_instruction +
                    price_instruction +
                    "–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∂–∏–≤—ã–º —è–∑—ã–∫–æ–º. "
                    "–í–ê–ñ–ù–û: –û–±—ä—ë–º –°–¢–†–û–ì–û 100-150 —Å–ª–æ–≤ (–Ω–µ –±–æ–ª—å—à–µ!). –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π —Ç–æ, —á—Ç–æ —É–∂–µ –±—ã–ª–æ —Å–∫–∞–∑–∞–Ω–æ.\n"
                    "–ê—Å–ø–µ–∫—Ç—ã –¥–ª—è —É—á—ë—Ç–∞:\n" + questions_block
                ),
            }
        )
        return messages

    def _strip_source_citations(self, text: str) -> str:
        """–ü–æ–ª–Ω–æ—Å—Ç—å—é —É–¥–∞–ª—è–µ—Ç –º–µ—Ç–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤–∏–¥–∞ [doc: filename.md] –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç–∞."""
        pattern = re.compile(r"\[doc:\s*[^\]]+\]")
        return pattern.sub("", text)

    # --- –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≥–ª–∞–¥–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ---
    def _remove_question_headings(self, text: str) -> str:
        """–£–±–∏—Ä–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏-–∑–∞–≥–æ–ª–æ–≤–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥—É–±–ª–∏—Ä—É—é—Ç –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã,
        –≤–∏–¥–∞ '1. **...?...**' –∏–ª–∏ '- **...?...**' –≤ –Ω–∞—á–∞–ª–µ –±–ª–æ–∫–æ–≤. –ù–µ —Ç—Ä–æ–≥–∞–µ—Ç –æ–±—ã—á–Ω—ã–µ —Å–ø–∏—Å–∫–∏.
        """
        lines = text.splitlines()
        cleaned_lines: List[str] = []
        heading_re = re.compile(r"^\s*(?:\d+\.|-)\s*\*\*[^*\n]*\?\*\*\s*$")
        for ln in lines:
            if heading_re.match(ln):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∞–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                continue
            cleaned_lines.append(ln)
        # –°–∂–∞—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        out: List[str] = []
        empty = 0
        for ln in cleaned_lines:
            if ln.strip() == "":
                empty += 1
                if empty <= 2:
                    out.append(ln)
            else:
                empty = 0
                out.append(ln)
        return "\n".join(out).strip()

    def _humanize_missing_info(self, text: str) -> str:
        """–ó–∞–º–µ–Ω—è–µ—Ç —Å—É—Ö–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –±–æ–ª–µ–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–µ.
        –ü—Ä–∏–º–µ—Ä—ã: "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö", "–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ —É–∫–∞–∑–∞–Ω–æ" ‚Üí —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è —Ñ—Ä–∞–∑–∞.
        """
        replacements = [
            r"–Ω–µ—Ç\s+–¥–∞–Ω–Ω—ã—Ö\s+–≤\s+–¥–æ–∫—É–º–µ–Ω—Ç(–∞—Ö|–∞—Ö–∞—Ö|–∞—Ö–∞—Ö)?",
            r"–≤\s+–¥–æ–∫—É–º–µ–Ω—Ç(–∞—Ö|–∞—Ö–∞—Ö|–∞—Ö–∞—Ö)?\s+–Ω–µ\s+—É–∫–∞–∑–∞–Ω–æ",
            r"–∏–Ω—Ñ–æ—Ä–º–∞—Ü(–∏–∏|–∏—è)\s+–≤\s+–¥–æ–∫—É–º–µ–Ω—Ç(–∞—Ö|–∞—Ö–∞—Ö|–∞—Ö–∞—Ö)?\s+–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
        ]
        friendly = "–í –Ω–∞—à–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö —ç—Ç–æ–≥–æ –Ω–µ—Ç."
        out = text
        for pat in replacements:
            out = re.sub(pat, friendly, out, flags=re.IGNORECASE)
        return out

    def _strip_service_labels(self, text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤–∏–¥–∞ '–ö–æ—Ä–æ—Ç–∫–æ:', '–í–∞–∂–Ω–æ:', '–ò—Ç–æ–≥–æ:', '–ú–æ–≥—É –ø–æ–º–æ—á—å:'
        –ü—Ä–∏ —ç—Ç–æ–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)."""
        out_lines: List[str] = []
        label_re = re.compile(r"^\s*(–ö–æ—Ä–æ—Ç–∫–æ|–í–∞–∂–Ω–æ|–ò—Ç–æ–≥–æ|–ú–æ–≥—É –ø–æ–º–æ—á—å)\s*:\s*(.*)$", re.IGNORECASE)
        for ln in text.splitlines():
            m = label_re.match(ln)
            if m:
                content_after = m.group(2).strip()
                if content_after:
                    out_lines.append(content_after)
                # –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –ª–µ–π–±–ª –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É
            else:
                out_lines.append(ln)
        return "\n".join(out_lines)

    def _strip_generic_cta(self, text: str) -> str:
        """–£–±–∏—Ä–∞–µ—Ç –Ω–∞–≤—è–∑—á–∏–≤—ã–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ CTA –≤—Ä–æ–¥–µ '–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã...' –∏ –ø–æ—Ö–æ–∂–∏–µ."""
        patterns = [
            r"^\s*–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å .*–≤–æ–ø—Ä–æ—Å",
            r"^\s*–ï—Å–ª–∏ –±—É–¥—É—Ç –≤–æ–ø—Ä–æ—Å—ã",
            r"^\s*–ì–æ—Ç–æ–≤(–∞|—ã)? –ø–æ–º–æ—á—å",
            r"^\s*–ú–æ–≥—É —É—Ç–æ—á–Ω–∏—Ç—å —É –º–µ–Ω–µ–¥–∂–µ—Ä–∞",
            r"^\s*–Ø –º–æ–≥—É .* (—É—Ç–æ—á–Ω–∏—Ç—å|–ø–æ–º–æ—á—å)",
        ]
        lines = [ln for ln in text.splitlines() if not any(re.search(p, ln, flags=re.IGNORECASE) for p in patterns)]
        # —Ç–∞–∫–∂–µ —É–¥–∞–ª–∏–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –∫–æ–Ω—Ü–µ
        while lines and lines[-1].strip() == "":
            lines.pop()
        return "\n".join(lines)

    # –£–¥–∞–ª—è–µ–º –º–µ—Ç–æ–¥ _stylize_response, —Ç–∞–∫ –∫–∞–∫ —Ç–µ–ø–µ—Ä—å —Å—Ç–∏–ª–∏–∑–∞—Ü–∏—è –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç
    
    def _final_sanitize(self, text: str) -> str:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞: —É–±–∏—Ä–∞–µ–º –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        out = text
        
        # –£–±–∏—Ä–∞–µ–º –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è
        out = out.replace("!", ".")
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π
        safe = out
        safe = re.sub(r"\b—Ç\.–¥\.", "—Ç_–¥", safe)
        safe = re.sub(r"\b—Ç\.–ø\.", "—Ç_–ø", safe)
        
        chunks = re.split(r"(?<=[\.\?\!])\s+|\n", safe)
        sentences: List[str] = []
        for ch in chunks:
            s = ch.strip()
            if s:
                sentences.append(s)
        
        seen = set()
        deduped: List[str] = []
        for s in sentences:
            key = re.sub(r"\s+", " ", s.lower()).strip()
            if key and key not in seen:
                seen.add(key)
                deduped.append(s)
        
        # –°–∫–ª–µ–π–∫–∞ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π
        text_out = " ".join(deduped)
        text_out = text_out.replace("—Ç_–¥", "—Ç.–¥.").replace("—Ç_–ø", "—Ç.–ø.")
        text_out = "\n".join(line.rstrip() for line in text_out.splitlines())
        text_out = re.sub(r"\n{3,}", "\n\n", text_out)
        return text_out.strip()
    
    def _sanitize_style(self, text: str) -> str:
        """–°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏."""
        return self._final_sanitize(text)
    
    def _should_add_offer(self, user_signal: str, history: list, offer: dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –¥–æ–±–∞–≤–ª—è—Ç—å offer (rate limiting)
        
        Args:
            user_signal: –¢–µ–∫—É—â–∏–π —Å–∏–≥–Ω–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            offer: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞
            
        Returns:
            True –µ—Å–ª–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å offer, False –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
        """
        if not history:
            return True  # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å
        
        # –î–ª—è anxiety_about_child - –Ω–µ —á–∞—â–µ —á–µ–º —Ä–∞–∑ –≤ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
        if user_signal == "anxiety_about_child":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            recent_assistant_messages = []
            for msg in history[-8:]:  # –°–º–æ—Ç—Ä–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 –ø–∞—Ä—ã
                if msg.get("role") == "assistant":
                    recent_assistant_messages.append(msg.get("content", ""))
            
            # –ï—Å–ª–∏ CTA –ø—Ä–æ —Å—Ç–µ—Å–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ—Ç–µ–π —É–∂–µ –±—ã–ª –Ω–µ–¥–∞–≤–Ω–æ
            for msg_content in recent_assistant_messages[-2:]:  # –í –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 2 –æ—Ç–≤–µ—Ç–∞—Ö
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã CTA –¥–ª—è anxiety
                anxiety_cta_markers = [
                    "—Ä–æ–¥–∏—Ç–µ–ª–µ–π —Å—Ç–µ—Å–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ—Ç–µ–π",
                    "–ø—Ä–æ–±–Ω–æ–µ –∑–∞–Ω—è—Ç–∏–µ",
                    "üíö –ú—ã –ø–æ–Ω–∏–º–∞–µ–º –≤–∞—à–∏ –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏—è",
                    "–ü–µ—Ä–≤–æ–µ –∑–∞–Ω—è—Ç–∏–µ –≤—Å–µ–≥–¥–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–µ",
                    "–ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –Ω–∞—à –ø–æ–¥—Ö–æ–¥ –≤–∞—à–µ–º—É —Ä–µ–±–µ–Ω–∫—É"
                ]
                if any(marker in msg_content for marker in anxiety_cta_markers):
                    print("üîÑ Rate limiting: CTA –¥–ª—è anxiety –±—ã–ª –Ω–µ–¥–∞–≤–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    return False
        
        # –î–ª—è ready_to_buy - —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç
        # (–æ–Ω–∞ —É–∂–µ –µ—Å—Ç—å –≤ get_offer)
        
        return True
    
    def _inject_offer(self, response: str, offer: dict) -> str:
        """–û—Ä–≥–∞–Ω–∏—á–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –∫–æ–Ω–µ—Ü –æ—Ç–≤–µ—Ç–∞
        
        Args:
            response: –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç
            offer: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –∏–∑ offers_catalog
            
        Returns:
            –û—Ç–≤–µ—Ç —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º
        """
        # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç–æ—á–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
        response_trimmed = response.rstrip()
        if response_trimmed.endswith('.'):
            response_trimmed = response_trimmed[:-1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç placement
        if offer.get("placement") == "end_with_urgency":
            transition = "!\n\n"  # –í–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫ –¥–ª—è urgency
        else:
            transition = ".\n\n"  # –û–±—ã—á–Ω–∞—è —Ç–æ—á–∫–∞
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        return f"{response_trimmed}{transition}{offer['text']}"
